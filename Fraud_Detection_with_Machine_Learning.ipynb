{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py8Dk1pdhv02"
   },
   "source": [
    "# Fraud Detection with Machine Learning\n",
    "\n",
    "This project aims to build a **fraud detection system** using machine learning on financial transaction data.\n",
    "\n",
    "The goal is to:\n",
    "- Understand and visualize transaction patterns.\n",
    "- Build a predictive model to detect potential frauds.\n",
    "- Optimize for both **accuracy** and **recall** to minimize false negatives (missed frauds).\n",
    "- Deploy the model as an interactive dashboard later.\n",
    "\n",
    "**Dataset Info:**\n",
    "- File: `Fraud.csv`\n",
    "- Rows: 6,362,620\n",
    "- Columns: 11  \n",
    "- Source: Synthetic dataset simulating financial transactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PnxXD_biFgS"
   },
   "source": [
    "##  1. Import Required Libraries\n",
    "\n",
    "We start by importing the essential Python libraries for:\n",
    "- **Data manipulation:** `pandas`, `numpy`\n",
    "- **Visualization:** `matplotlib`, `seaborn`\n",
    "- **Memory management:** `gc`\n",
    "- **Warning control:** `warnings`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIZA9qKihvUf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "# To suppress unnecessary warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Show all columns when displaying dataframes\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eDphMEKiNFM"
   },
   "source": [
    "## 2: Load the Dataset\n",
    "\n",
    "The dataset `Fraud.csv` contains transaction details such as:\n",
    "- Step (time step of the transaction)\n",
    "- Type (transaction type: PAYMENT, TRANSFER, etc.)\n",
    "- Amount\n",
    "- Source and destination account balances\n",
    "- Fraud indicators (`isFraud` and `isFlaggedFraud`)\n",
    "\n",
    "We’ll specify `dtype` for each column to reduce memory usage during loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "B0tJSwoViJ6z",
    "outputId": "df8158ab-7cbe-4465-88f3-a8f1f50d0338"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/content/Fraud.csv'   # Update if stored elsewhere\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "\n",
    "dtype_map = {\n",
    "    'step': 'int32',\n",
    "    'type': 'category',\n",
    "    'amount': 'float32',\n",
    "    'oldbalanceOrg': 'float32',\n",
    "    'newbalanceOrig': 'float32',\n",
    "    'oldbalanceDest': 'float32',\n",
    "    'newbalanceDest': 'float32',\n",
    "    'isFraud': 'int8',\n",
    "    'isFlaggedFraud': 'int8'\n",
    "}\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, dtype=dtype_map, low_memory=False)\n",
    "\n",
    "print(\" Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Memory usage (MB): {round(df.memory_usage().sum() / 1024**2, 2)}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrsLcdvA0y1_"
   },
   "source": [
    "## 3.Dataset Overview\n",
    "\n",
    "Now, let's quickly inspect:\n",
    "- The data types of each column  \n",
    "- Null or missing values  \n",
    "- A few descriptive statistics  \n",
    "- Class balance between fraudulent and non-fraudulent transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 942
    },
    "id": "5bo_1W1N0kYF",
    "outputId": "2be571e4-3354-4fdb-f497-2fbbf464629f"
   },
   "outputs": [],
   "source": [
    "# Data types and non-null counts\n",
    "print(\"Data Info:\")\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Basic descriptive statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Fraud ratio\n",
    "fraud_ratio = df['isFraud'].mean() * 100\n",
    "print(f\"\\nFraudulent transactions ratio: {fraud_ratio:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnMOWWnC1QbL"
   },
   "source": [
    "## 4.Exploratory Data Analysis (EDA)\n",
    "\n",
    "Before building a model, it's important to explore the dataset to understand:\n",
    "- Which transaction types are most common?\n",
    "- How much money do fraudulent transactions involve?\n",
    "- How is the balance changing before and after a transaction?\n",
    "- What’s the imbalance between fraud and non-fraud classes?\n",
    "\n",
    "Let's start by analyzing transaction types and fraud distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1DCxr_u1UmG"
   },
   "source": [
    "### 4.1 Distribution of Transaction Types\n",
    "\n",
    "We’ll check the frequency of each transaction type and how often fraud occurs in each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inU7yN2m2D5j"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxAfSZ4v2G0K"
   },
   "source": [
    "### 4.1 Distribution of Transaction Types (Interactive)\n",
    "\n",
    "This chart shows how frequently each transaction type occurs,  \n",
    "and allows you to hover over bars to view exact counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "7tl6evMZ1KGZ",
    "outputId": "ec5d3991-e54d-47c2-ba50-1e6f55126284"
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    df,\n",
    "    x='type',\n",
    "    color='isFraud',\n",
    "    barmode='group',\n",
    "    title='Distribution of Transaction Types (Fraud vs Non-Fraud)',\n",
    "    color_discrete_map={0: 'blue', 1: 'red'}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Transaction Type',\n",
    "    yaxis_title='Count',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzLZEaPY2NW5"
   },
   "source": [
    "### 4.2 Transaction Amount Distribution Over Time\n",
    "\n",
    "Histogram showing how transaction amounts evolve across time steps.\n",
    "This helps us see if certain time periods have higher fraud concentration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "NuLMe5JG13vK",
    "outputId": "bc216059-5f87-4ed8-9636-2bb8bb7b067e"
   },
   "outputs": [],
   "source": [
    "# Limit for visibility\n",
    "sample = df[df['amount'] < 50000].sample(50000, random_state=42)\n",
    "\n",
    "fig = px.histogram(\n",
    "    sample,\n",
    "    x='amount',\n",
    "    color='isFraud',\n",
    "    nbins=50,\n",
    "    animation_frame='step',\n",
    "    title='Transaction Amount Distribution Over Time (Animated)',\n",
    "    color_discrete_map={0: 'lightblue', 1: 'red'}\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title='Transaction Amount',\n",
    "    yaxis_title='Count',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83vRrVB92aYN"
   },
   "source": [
    "### 4.3 Origin Account Balance Changes\n",
    "\n",
    " scatter plot that shows how account balances change during transactions.  \n",
    "Fraudulent ones often display abrupt or illogical balance jumps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "cVlgekRB2Tvb",
    "outputId": "0aa22fb2-2b81-4ef2-b6a8-869eee22007b"
   },
   "outputs": [],
   "source": [
    "sample = df.sample(10000, random_state=42).copy()\n",
    "sample['balance_diff'] = sample['oldbalanceOrg'] - sample['newbalanceOrig']\n",
    "\n",
    "fig = px.scatter(\n",
    "    sample,\n",
    "    x='oldbalanceOrg',\n",
    "    y='newbalanceOrig',\n",
    "    color='isFraud',\n",
    "    animation_frame='step',\n",
    "    size='amount',\n",
    "    title='Origin Account Balances Before vs After (Animated)',\n",
    "    color_discrete_map={0: 'green', 1: 'red'},\n",
    "    hover_data=['amount', 'type']\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title='Old Balance (Origin)',\n",
    "    yaxis_title='New Balance (Origin)',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmdUY5yG2t3O"
   },
   "source": [
    "### 4.4 Fraud Rate by Transaction Type\n",
    "\n",
    " Bar chart showing the percentage of fraudulent transactions per type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "TPYWf8GZ2hWZ",
    "outputId": "8008102c-2b1e-4967-bdfb-da7b5c8aed6b"
   },
   "outputs": [],
   "source": [
    "fraud_rate = df.groupby('type')['isFraud'].mean().reset_index()\n",
    "fraud_rate['isFraud'] *= 100\n",
    "\n",
    "fig = px.bar(\n",
    "    fraud_rate,\n",
    "    x='type',\n",
    "    y='isFraud',\n",
    "    text='isFraud',\n",
    "    title='Fraud Percentage by Transaction Type',\n",
    "    color='isFraud',\n",
    "    color_continuous_scale='Reds'\n",
    ")\n",
    "fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')\n",
    "fig.update_layout(\n",
    "    xaxis_title='Transaction Type',\n",
    "    yaxis_title='Fraud Rate (%)',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvJc413O3B13"
   },
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "To improve model performance, we'll create additional features that help capture hidden relationships in the data.\n",
    "\n",
    "### Features to Add:\n",
    "1. **Type Encoding:** Convert categorical `type` to numeric codes.\n",
    "2. **Balance Changes:** Calculate how account balances change before and after each transaction.\n",
    "3. **Log Amount:** Apply logarithmic transformation to large transaction amounts.\n",
    "4. **Transaction Ratios:** Compare amount to available balance.\n",
    "\n",
    "These transformations make the model more interpretable and powerful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 724
    },
    "id": "PO5P6Y8I20FC",
    "outputId": "0f90387b-e68d-4f8c-8e2a-2ba87be7a7a6"
   },
   "outputs": [],
   "source": [
    "# 1. Encode transaction type\n",
    "df['type_code'] = df['type'].map({\n",
    "    'PAYMENT': 0,\n",
    "    'TRANSFER': 1,\n",
    "    'CASH_OUT': 2,\n",
    "    'DEBIT': 3\n",
    "}).fillna(4).astype('int8')\n",
    "\n",
    "# 2. Compute balance change features\n",
    "df['delta_orig'] = df['oldbalanceOrg'] - df['newbalanceOrig']\n",
    "df['delta_dest'] = df['newbalanceDest'] - df['oldbalanceDest']\n",
    "\n",
    "# 3. Log-transform amount to handle skew\n",
    "df['amt_log'] = np.log1p(df['amount'])\n",
    "\n",
    "# 4. Transaction ratio: amount relative to sender's original balance\n",
    "df['trans_ratio'] = np.where(df['oldbalanceOrg'] > 0,\n",
    "                             df['amount'] / (df['oldbalanceOrg'] + 1e-5),\n",
    "                             0).astype('float32')\n",
    "\n",
    "# Check sample of new features\n",
    "df[['amount', 'delta_orig', 'delta_dest', 'amt_log', 'trans_ratio', 'type_code']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1_rjKyQ3TVx"
   },
   "source": [
    "### 5.1 Handling Missing and Infinite Values\n",
    "\n",
    "Some columns may contain invalid entries such as `NaN`, `inf`, or `-inf`.\n",
    "We’ll replace those with safe defaults to avoid model training errors.\n",
    "\n",
    "We’ll **skip categorical columns** while filling numeric columns with `0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQoN0lzn3JsS",
    "outputId": "c09281f3-013c-4aed-d6dc-11cf95f5d6b3"
   },
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# Exclude the 'type' column when filling NaN values\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().any():\n",
    "        if df[col].dtype.name != 'category':\n",
    "            df[col].fillna(0, inplace=True)\n",
    "\n",
    "print(\" Missing values handled successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cvvv2vsq3zhV"
   },
   "source": [
    "## 6. Prepare Training and Validation Sets\n",
    "\n",
    "We'll now split the dataset into **train** and **validation** sets for model training.\n",
    "Given the large dataset size, we’ll sample for efficient training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPIY23p_3bYp",
    "outputId": "ee75c6fd-80b2-4cec-dc81-f6d12242b725"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Choose relevant features\n",
    "feature_cols = [\n",
    "    'amount', 'oldbalanceOrg', 'newbalanceOrig',\n",
    "    'oldbalanceDest', 'newbalanceDest',\n",
    "    'delta_orig', 'delta_dest', 'amt_log',\n",
    "    'trans_ratio', 'type_code'\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['isFraud']\n",
    "\n",
    "# Downsample for training efficiency (optional)\n",
    "df_sample = df.sample(500000, random_state=42)\n",
    "X = df_sample[feature_cols]\n",
    "y = df_sample['isFraud']\n",
    "\n",
    "# Split into train-validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Validation shape: {X_val.shape}\")\n",
    "print(f\"Fraud ratio in train: {y_train.mean():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syZZwReg3-Tf"
   },
   "source": [
    "## 7.Model Training (LightGBM)\n",
    "\n",
    "We use **LightGBM**, a fast and efficient gradient boosting model well-suited for large datasets and imbalanced classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "v9RqGoKU36B_",
    "outputId": "12f49166-9c28-44a0-9d7c-f3f5f2123572"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "\n",
    "# Calculate class weight for imbalance\n",
    "scale_pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()\n",
    "\n",
    "# Initialize model\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train with callbacks for logging and early stopping\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[early_stopping(stopping_rounds=50), log_evaluation(period=50)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRvz39wC4Qfs"
   },
   "source": [
    "##8. Model Evaluation\n",
    "\n",
    "We'll evaluate the model using Precision, Recall, F1-score, and AUC.  \n",
    "High **recall** is crucial for fraud detection — we prefer to catch more frauds, even if it means some false positives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeEGLhGd4DBz",
    "outputId": "fbdbb542-dbc2-4956-c228-46db39f40bd8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# AUC Score\n",
    "roc_auc = roc_auc_score(y_val, y_proba)\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Precision-Recall curve\n",
    "prec, rec, th = precision_recall_curve(y_val, y_proba)\n",
    "pr_auc = auc(rec, prec)\n",
    "print(f\"PR-AUC: {pr_auc:.4f}\")\n",
    "\n",
    "# Choose threshold with best F1\n",
    "f1_scores = 2 * (prec * rec) / (prec + rec)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_threshold = th[best_idx]\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold:.4f}\")\n",
    "print(f\"Precision: {prec[best_idx]:.4f}, Recall: {rec[best_idx]:.4f}, F1: {f1_scores[best_idx]:.4f}\")\n",
    "\n",
    "# Final classification report\n",
    "y_pred = (y_proba >= best_threshold).astype(int)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6Ck8j7T4d0E"
   },
   "source": [
    "##9. Save the Trained Model\n",
    "\n",
    "We'll save the trained LightGBM model so we can load it later in a Streamlit dashboard or API for live predictions.\n",
    "We’ll use the `joblib` library, which efficiently stores large model objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FNXgRXtU4VhF",
    "outputId": "a774b920-aa39-4e05-eb04-658b99708368"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create folder if not exists\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = \"model/fraud_model_slim.pkl\"\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Save metadata (features + threshold)\n",
    "metadata = {\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"best_threshold\": float(best_threshold)\n",
    "}\n",
    "with open(\"model/metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(f\" Model saved to: {model_path}\")\n",
    "print(f\" Metadata saved to: model/metadata.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLc0K6Uv4tMl"
   },
   "source": [
    "## 10. Feature Importance\n",
    "\n",
    "LightGBM provides feature importance scores showing how much each feature contributes to the model’s predictions.\n",
    "We’ll visualize this as a bar chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "e2_yMNqZ4hNQ",
    "outputId": "a44e5826-66ae-470d-ae65-dfeb2c458fbe"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_cols,\n",
    "    \"Importance\": model.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=True)\n",
    "\n",
    "fig = px.bar(\n",
    "    importance_df,\n",
    "    x=\"Importance\",\n",
    "    y=\"Feature\",\n",
    "    orientation=\"h\",\n",
    "    title=\"Feature Importance (LightGBM)\",\n",
    "    color=\"Importance\",\n",
    "    color_continuous_scale=\"Blues\"\n",
    ")\n",
    "fig.update_layout(template=\"plotly_white\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eco9WDm40N5"
   },
   "source": [
    "##  11. Model Explainability using SHAP\n",
    "\n",
    "To understand why the model predicts a transaction as fraud or not, we use **SHAP (SHapley Additive exPlanations)**.\n",
    "SHAP values explain the contribution of each feature to individual predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlDqhTcn4xmv"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Initialize SHAP explainer (TreeExplainer works best with LightGBM)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Use a subset of validation data for speed\n",
    "sample_X = X_val.sample(1000, random_state=42)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer.shap_values(sample_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BTjMQP56TFa"
   },
   "source": [
    "### 11.1 SHAP Summary Plot\n",
    "\n",
    "The summary plot shows which features have the strongest influence on fraud prediction across many samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "lu-8EnqE6EBj",
    "outputId": "2d69b704-4d51-4693-d747-1d8f3bca4ccb"
   },
   "outputs": [],
   "source": [
    "# Visual summary\n",
    "shap.summary_plot(shap_values, sample_X, plot_type=\"dot\", show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7mZzWLh6X7d"
   },
   "source": [
    "### 11.2 Single Transaction Explanation\n",
    "\n",
    "Let's take one random transaction and visualize how each feature contributes to its fraud score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "JsPNyiSx6V8c",
    "outputId": "f5b08026-b932-4d05-f407-72f37d70ffff"
   },
   "outputs": [],
   "source": [
    "\n",
    "single = X_val.sample(1, random_state=42)\n",
    "shap_single = explainer.shap_values(single)\n",
    "\n",
    "\n",
    "if isinstance(shap_single, list):\n",
    "    shap_single = shap_single[0]\n",
    "\n",
    "\n",
    "shap.plots.bar(shap.Explanation(values=shap_single, base_values=explainer.expected_value, data=single))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KDE-QMU-vTy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
